apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  annotations:
    config.linkerd.io/proxy-cpu-limit: 1000m
    config.linkerd.io/proxy-cpu-request: 100m
    config.linkerd.io/skip-outbound-ports: "443"
    linkerd.io/inject: enabled
    meta.helm.sh/release-name: carver-workflows
    meta.helm.sh/release-namespace: carver-workflows-test-smohar
    workflows.argoproj.io/kill-cmd-linkerd-proxy: '["/usr/lib/linkerd/linkerd-await",
      "-S", "/bin/sleep", "0"]'
  name: carver-job
  namespace: carver-workflows-test-smohar
spec:
  arguments:
    parameters:
    - name: image
      value: 473168459077.dkr.ecr.us-west-2.amazonaws.com/carver:latest
    - name: s3Bucket
      value: com-cibo-salus-at-scale-alt
    - name: geomancerHost
      value: geomancer.geomancer-dev.svc.cluster.local
    - name: geomancerPort
      value: "50051"
    - name: sylvesterUri
      value: http://sylvester-dev.sylvester-dev.svc.cluster.local
    - name: cropnosisUri
      value: http://cropnosis-dev.cropnosis-dev.svc.cluster.local
  entrypoint: carver-job
  templates:
  - inputs:
      parameters:
      - name: jobPath
      - name: image
        value: 473168459077.dkr.ecr.us-west-2.amazonaws.com/carver:latest
      - name: s3Bucket
        value: com-cibo-salus-at-scale-alt
      - name: useSpotInstances
        value: "no"
    metadata: {}
    name: carver-job
    outputs: {}
    parallelism: 24
    steps:
    - - arguments:
          parameters:
          - name: baseS3URL
            value: s3://{{inputs.parameters.s3Bucket}}/{{inputs.parameters.jobPath}}
          - name: scenarioLibraryURL
            value: s3://{{inputs.parameters.s3Bucket}}/scenario-library
        name: setup
        template: setup
    - - arguments:
          parameters:
          - name: baseS3URL
            value: s3://{{inputs.parameters.s3Bucket}}/{{inputs.parameters.jobPath}}
          - name: image
            value: '{{inputs.parameters.image}}'
          - name: useSpotInstances
            value: '{{inputs.parameters.useSpotInstances}}'
        name: geometry-expansion
        template: geometry-expansion
    - - arguments:
          parameters:
          - name: runYear
            value: '{{=jsonpath(steps.setup.outputs.parameters.jobRequest, ''$.jobYear'')}}'
          - name: runTitle
            value: '{{=jsonpath(steps.setup.outputs.parameters.jobRequest, ''$.jobId'')}}'
          - name: runVersion
            value: '{{=jsonpath(steps.setup.outputs.parameters.jobRequest, ''$.jobVersion'')}}'
          - name: boundaryId
            value: '{{item}}'
          - name: image
            value: '{{inputs.parameters.image}}'
          - name: useSpotInstances
            value: '{{inputs.parameters.useSpotInstances}}'
          - name: s3Bucket
            value: '{{inputs.parameters.s3Bucket}}'
          - name: salusVariant
            value: '{{= trim(steps.setup.outputs.parameters.salusVariant)}}'
        name: simulation
        templateRef:
          name: generic-runner
          template: execute-generic-runner-steps
        withParam: '{{steps.setup.outputs.parameters.boundaries}}'
    - - arguments:
          parameters:
          - name: targetPrefix
            value: '{{inputs.parameters.jobPath}}'
          - name: targetBucket
            value: '{{inputs.parameters.s3Bucket}}'
          - name: failIfIncomplete
            value: "false"
          - name: image
            value: '{{inputs.parameters.image}}'
        name: aggregation
        templateRef:
          name: status-aggregator
          template: execute-status-aggregator
    - - arguments:
          parameters:
          - name: runYear
            value: '{{=jsonpath(steps.setup.outputs.parameters.jobRequest, ''$.jobYear'')}}'
          - name: runTitle
            value: '{{=jsonpath(steps.setup.outputs.parameters.jobRequest, ''$.jobId'')}}'
          - name: runVersion
            value: '{{=jsonpath(steps.setup.outputs.parameters.jobRequest, ''$.jobVersion'')}}'
          - name: reportType
            value: '{{=jsonpath(steps.setup.outputs.parameters.reportingParams, ''$.reportType'')}}'
          - name: reportAggregationLevel
            value: '{{=jsonpath(steps.setup.outputs.parameters.reportingParams, ''$.aggregationLevel'')}}'
          - name: boundaryId
            value: '{{item}}'
          - name: image
            value: '{{inputs.parameters.image}}'
          - name: useSpotInstances
            value: '{{inputs.parameters.useSpotInstances}}'
          - name: s3Bucket
            value: '{{inputs.parameters.s3Bucket}}'
        name: report-generation-per-boundary
        templateRef:
          name: scope3-report-generator
          template: execute-scope3-report-generator
        withParam: '{{steps.setup.outputs.parameters.boundaries}}'
    - - arguments:
          parameters:
          - name: image
            value: '{{inputs.parameters.image}}'
          - name: baseS3URL
            value: s3://{{inputs.parameters.s3Bucket}}/{{inputs.parameters.jobPath}}
          - name: reportName
            value: default
        name: combine-reports
        templateRef:
          name: combine-reports
          template: execute-combine-reports
    - - arguments:
          parameters:
          - name: targetPrefix
            value: '{{inputs.parameters.jobPath}}'
          - name: targetBucket
            value: '{{inputs.parameters.s3Bucket}}'
          - name: useSpotInstances
            value: '{{inputs.parameters.useSpotInstances}}'
        name: carver-qa-final
        templateRef:
          name: carver-scope3-qa
          template: execute-carver-qa
  - containerSet:
      containers:
      - args:
        - |
          if ! aws s3 ls {{inputs.parameters.baseS3URL}}; then
            echo "Error: The base S3 URL does not exist."
            exit 1
          fi
          if ! aws s3 ls {{inputs.parameters.baseS3URL}}/job.json; then
            if ! aws s3 ls {{inputs.parameters.baseS3URL}}/job.yaml; then
              echo "Error: The job request input does not exist."
              exit 1
            fi
          fi
          if ! aws s3 ls {{inputs.parameters.scenarioLibraryURL}}; then
            echo "Error: The scenario library S3 URL does not exist."
            exit 1
          fi
        command:
        - sh
        - -c
        image: amazon/aws-cli:2.17.13
        name: pre-flight-check
        resources:
          limits:
            ephemeral-storage: 500Mi
            memory: 512M
          requests:
            cpu: "4"
            memory: 512M
      - args:
        - |
          mkdir -p /stage/scenariomode/scenarios
          aws s3 sync {{inputs.parameters.baseS3URL}} /stage/ --exclude "**/batchmode" --exclude "**/inputs" --exclude "**/outputs"
        command:
        - sh
        - -c
        dependencies:
        - pre-flight-check
        image: amazon/aws-cli:2.17.13
        name: sync-job-inputs-from-s3
        resources:
          limits:
            ephemeral-storage: 500Mi
            memory: 512M
          requests:
            cpu: "4"
            memory: 512M
      - args:
        - |
          if test -f /stage/job.yaml; then
            cat /stage/job.yaml | yq -o json > /stage/job.json
            echo "Converted job.yaml to JSON."
          fi
          if ! test -f /stage/config.json; then
            cat /stage/job.json | jq -r '.simulation | pick(.builderName)' > /stage/config.json
            echo "Wrote config.json from job request."
            cat /stage/config.json
          fi

          cat /stage/job.json | jq -r '.simulation | .salusVariant // "Mainline"' > /stage/salusVariant.txt
          echo "Wrote salusVariant.txt from job request."
          cat /stage/salusVariant.txt

          cat /stage/job.json | jq -r '[.boundaries[].id]' > /stage/boundaries.json
          cat /stage/job.json | jq -r \
            '.report?.scope3? | { reportType: (.intervention | if . == true then "Intervention" else "SupplyShed" end), aggregationLevel: (.aggregationLevel | if . != null then . else "PerBoundary" end)}' \
            > /stage/reportingParams.json
        command:
        - sh
        - -c
        dependencies:
        - sync-job-inputs-from-s3
        image: ddev/ddev-utilities:latest
        name: config-expansion
        resources:
          limits:
            ephemeral-storage: 500Mi
            memory: 512M
          requests:
            cpu: "4"
            memory: 512M
      - args:
        - |
          import json, os
          sf = '/stage/scenariomode/scenarios/scenarios.json'
          sp = '/stage/scenariomode/scenarios/scenariopointer.txt'
          request = json.load(open('/stage/job.json', 'r'))
          if request['simulation'].get('scenario'):
            if os.path.exists(sf):
              print("Error: The inline scenario in the job request would overwrite scenario.json on S3.")
              exit(1)
            with open(sf, 'w') as f:
              json.dump(request['simulation']['scenario'], f)
              print("Wrote inline scenario to ", sf)
          else:
            scenarioFilename = request['simulation'].get('scenarioLibraryFilename')
            if scenarioFilename:
              if os.path.exists(sp):
                print("Error: The scenarioLibraryFilename in the job request would overwrite scenariopointer.txt on S3.")
              with open(sp, 'w') as f:
                f.write(scenarioFilename)
                print("Wrote new scenario pointer ", scenarioFilename, " to ", sp)
        command:
        - python
        - -c
        dependencies:
        - config-expansion
        - sync-job-inputs-from-s3
        image: python:alpine3.6
        name: scenario-expansion-1
        resources:
          limits:
            ephemeral-storage: 500Mi
            memory: 512M
          requests:
            cpu: "4"
            memory: 512M
      - args:
        - |
          if test -f /stage/scenariomode/scenarios/scenariopointer.txt; then
            aws s3 cp "{{inputs.parameters.scenarioLibraryURL}}/"$(cat /stage/scenariomode/scenarios/scenariopointer.txt) /stage/scenarios.tmpl.json \
              || (echo "Error: Could not copy scenario library from S3." && exit 1)
            echo "Copied library scenario from S3 to /stage/scenarios.tmpl.json."
            rm /stage/scenariomode/scenarios/scenariopointer.txt
            echo "Removed scenariopointer.txt."
          fi
        command:
        - sh
        - -c
        - -e
        dependencies:
        - scenario-expansion-1
        image: amazon/aws-cli:2.17.13
        name: scenario-expansion-2
        resources:
          limits:
            ephemeral-storage: 500Mi
            memory: 512M
          requests:
            cpu: "4"
            memory: 512M
      - args:
        - |
          import json, os, re
          job = json.load(open('/stage/job.json', 'r'))
          if os.path.exists('/stage/scenarios.tmpl.json'):
            with open('/stage/scenarios.tmpl.json', 'r') as fin:
                scenarios = re.sub(r'{{(\w+)}}', lambda m: "%s" % job["simulation"].get(m.group(1)), fin.read())
                with open('/stage/scenariomode/scenarios/scenarios.json', 'w') as fout:
                    fout.write(scenarios)
                    print("Copied scenarios from library template to scenariomode/scenarios/scenarios.json with variable substitution.")
                os.unlink('/stage/scenarios.tmpl.json')
        command:
        - python
        - -c
        dependencies:
        - scenario-expansion-2
        image: python:alpine3.6
        name: scenario-expansion-3
        resources:
          limits:
            ephemeral-storage: 500Mi
            memory: 512M
          requests:
            cpu: "4"
            memory: 512M
      - args:
        - |
          aws s3 sync /stage/ {{inputs.parameters.baseS3URL}}
        command:
        - sh
        - -c
        dependencies:
        - scenario-expansion-3
        - config-expansion
        image: amazon/aws-cli:2.17.13
        name: main
        resources:
          limits:
            ephemeral-storage: 500Mi
            memory: 512M
          requests:
            cpu: "4"
            memory: 512M
      volumeMounts:
      - mountPath: /stage
        name: workspace
    inputs:
      parameters:
      - name: baseS3URL
      - name: scenarioLibraryURL
    metadata: {}
    name: setup
    outputs:
      parameters:
      - name: jobRequest
        valueFrom:
          path: /stage/job.json
      - name: boundaries
        valueFrom:
          path: /stage/boundaries.json
      - name: reportingParams
        valueFrom:
          path: /stage/reportingParams.json
      - name: salusVariant
        valueFrom:
          path: /stage/salusVariant.txt
    serviceAccountName: carverworkflowrole
    volumes:
    - emptyDir: {}
      name: workspace
  - container:
      args:
      - -main
      - com.cibo.carver.app.geometrystaging.GeometryExpander
      - --
      - --jobRequestURL
      - '{{inputs.parameters.baseS3URL}}/job.json'
      - --enableOverwrite
      - "true"
      command:
      - /opt/docker/bin/carver
      env:
      - name: GEOMANCER_GRPC_HOST
        value: '{{workflow.parameters.geomancerHost}}'
      - name: CONTINUUM_DATA
        value: /tmp/.continuum
      - name: JAVA_OPTS
        value: -XX:MaxRAMPercentage=50 -XX:+UseG1GC
      image: '{{inputs.parameters.image}}'
      imagePullPolicy: Always
      name: ""
      resources:
        limits:
          ephemeral-storage: 1Gi
          memory: 8Gi
        requests:
          cpu: "4"
          memory: 8Gi
    inputs:
      parameters:
      - name: baseS3URL
      - name: image
      - name: useSpotInstances
    metadata:
      annotations:
        config.linkerd.io/proxy-cpu-limit: 1000m
        config.linkerd.io/proxy-cpu-request: 100m
        config.linkerd.io/skip-outbound-ports: "443"
        linkerd.io/inject: enabled
        workflows.argoproj.io/kill-cmd-linkerd-proxy: '["/usr/lib/linkerd/linkerd-await",
          "-S", "/bin/sleep", "0"]'
      labels:
        template: geometry-expansion
    name: geometry-expansion
    nodeSelector:
      spot: "no"
    outputs: {}
    podSpecPatch: '{"containers":[{"name":"main", "nodeSelector": {"spot": "{{inputs.parameters.useSpotInstances}}"}}]}'
    retryStrategy:
      backoff:
        duration: 5s
        factor: "2"
      limit: "3"
      retryPolicy: Always
    serviceAccountName: carverworkflowrole
